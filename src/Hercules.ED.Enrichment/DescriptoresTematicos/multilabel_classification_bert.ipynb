{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_multilabel_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OecqFOL-i8dK"
      },
      "source": [
        "# PARAMETERS\n",
        "ID = 'hercules_papers_l0_5000_mbert'  # used to determine output directory for checkpoints\n",
        "DATASET = 'hercules.papers.l0.5000'  # all datasets are defined later in this script\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "SEQ_LEN = 256\n",
        "CHECKPOINT_FPATH = f\"gs://hercules_zbeloki/checkpoints/{ID}/\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3JnEbpsfQN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b380cb9c-1773-44f2-bdf6-dc20656307ef"
      },
      "source": [
        "!pip install -q tensorflow-text\n",
        "!pip install -q tf-models-official\n",
        "!pip install -q tensorflow-addons"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.6 MB 32 kB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 90 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 32.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 55.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 35.8 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiVhiIhZegnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbc45cdf-c777-4ea7-c4c9-9fe8c3815dfc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  # to create AdamW optimizer\n",
        "from tensorflow_addons.metrics import MultiLabelConfusionMatrix\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "from google.colab import auth, drive\n",
        "\n",
        "import random\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxQvumBHfOHh",
        "outputId": "e72426dc-aeb2-468f-8d6d-ce016b88ff94"
      },
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    print(\"TPU\")\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(\"No TPU\")\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on TPU  ['10.90.13.122:8470']\n",
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.90.13.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.90.13.122:8470\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TPU\n",
            "REPLICAS:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t31oUl7g7RdG",
        "outputId": "6bc9f0b7-bf2c-4c43-f8d5-1dcc321447fb"
      },
      "source": [
        "# authenticate in Google in order to get access to Google Cloud Bucket\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project hercules-315409"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb6VJ5KUl8JW"
      },
      "source": [
        "# The following datasets are read from Google Cloud Bucket from this account: zbeloki@gmail.com. Change it as you need.\n",
        "DATASETS = {\n",
        "    # format: (file_location, number_entries, delimiter)\n",
        "    'sourceforge': {\n",
        "        'train': ('gs://hercules_zbeloki/sourceforge.train_oversampled_max.csv', 55840, ','),\n",
        "        'test': ('gs://hercules_zbeloki/sourceforge.test.csv', 8273, ','),\n",
        "        'dev': ('gs://hercules_zbeloki/sourceforge.dev.csv', 8273, ','),\n",
        "    },\n",
        "    'bioprotocol': {\n",
        "        'train': ('gs://hercules_zbeloki/bioprotocol.train_oversampled_max.csv', 4021, ','),\n",
        "        'test': ('gs://hercules_zbeloki/bioprotocol.test.csv', 529, ','),\n",
        "        'dev': ('gs://hercules_zbeloki/bioprotocol.dev.csv', 525, ','),\n",
        "    },\n",
        "    'hercules.papers.l0.5000': {\n",
        "        'train': ('gs://hercules_zbeloki/papers_l0_5000.train.oversampled.tsv', 16851, '\\t'),\n",
        "        'test': ('gs://hercules_zbeloki/papers_l0_5000.test.tsv', 3611, '\\t'),\n",
        "        'dev': ('gs://hercules_zbeloki/papers_l0_5000.dev.tsv', 3611, '\\t'),\n",
        "    },\n",
        "    'hercules.papers.l1.5000': {\n",
        "        'train': ('gs://hercules_zbeloki/papers_l1_5000.train.oversampled.tsv', 112595, '\\t'),\n",
        "        'test': ('gs://hercules_zbeloki/papers_l1_5000.test.tsv', 18594, '\\t'),\n",
        "        'dev': ('gs://hercules_zbeloki/papers_l1_5000.dev.tsv', 18594, '\\t'),\n",
        "    },\n",
        "    'hercules.papers.l2.5000': {\n",
        "        'train': ('gs://hercules_zbeloki/papers_dataset_5000.train.oversampled.tsv', 843065, '\\t'),\n",
        "        'test': ('gs://hercules_zbeloki/papers_dataset_5000.test.tsv', 105054, '\\t'),\n",
        "        'dev': ('gs://hercules_zbeloki/papers_dataset_5000.dev.tsv', 105054, '\\t'),\n",
        "    },\n",
        "    'hercules.papers.l2.10000': {\n",
        "        'train': ('gs://hercules_zbeloki/papers_l2_10000.train.oversampled.tsv', 1164501, '\\t'),\n",
        "        'test': ('gs://hercules_zbeloki/papers_l2_10000.test.tsv', 141616, '\\t'),\n",
        "        'dev': ('gs://hercules_zbeloki/papers_l2_10000.dev.tsv', 141616, '\\t'),\n",
        "    },\n",
        "    'hiekadi.location': {\n",
        "        'train': ('gs://hercules_zbeloki/hiekadi.location.train.tsv', 151434, '\\t'),\n",
        "        'test': ('gs://hercules_zbeloki/hiekadi.location.test.tsv', 18929, '\\t'),\n",
        "        'dev': ('gs://hercules_zbeloki/hiekadi.location.dev.tsv', 18929, '\\t'),\n",
        "    },\n",
        "}\n",
        "\n",
        "fpath_train = DATASETS[DATASET]['train'][0]\n",
        "fpath_test = DATASETS[DATASET]['test'][0]\n",
        "fpath_dev = DATASETS[DATASET]['dev'][0]\n",
        "\n",
        "n_train = DATASETS[DATASET]['train'][1]\n",
        "n_test = DATASETS[DATASET]['test'][1]\n",
        "n_dev = DATASETS[DATASET]['dev'][1]\n",
        "\n",
        "delim_train = DATASETS[DATASET]['train'][2]\n",
        "delim_test = DATASETS[DATASET]['test'][2]\n",
        "delim_dev = DATASETS[DATASET]['dev'][2]\n",
        "\n",
        "train_ds = tf.data.experimental.make_csv_dataset(fpath_train, BATCH_SIZE, num_epochs=1, field_delim=delim_train)\n",
        "dev_ds = tf.data.experimental.make_csv_dataset(fpath_dev, BATCH_SIZE, num_epochs=1, shuffle=False, field_delim=delim_dev)\n",
        "\n",
        "train_ds = train_ds.unbatch()\n",
        "dev_ds = dev_ds.unbatch()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-GtG_3QTg2N"
      },
      "source": [
        "def prepare_multihot_label(feats):\n",
        "  topic_labels = list(feats.values())[2:]\n",
        "  multihot_label = tf.stack(topic_labels, axis=0)\n",
        "  return (feats, multihot_label)\n",
        "\n",
        "train_ds = train_ds.map(prepare_multihot_label)\n",
        "dev_ds = dev_ds.map(prepare_multihot_label)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BtzXec4g8tv"
      },
      "source": [
        "train_ds = train_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dev_ds = dev_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "train_steps_per_epoch = int(n_train / BATCH_SIZE)\n",
        "dev_steps_per_epoch = int(n_dev / BATCH_SIZE)\n",
        "\n",
        "num_classes = next(iter(train_ds.take(1)))[1].shape[1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4t6-SjjfbOq"
      },
      "source": [
        "os.environ[\"TFHUB_MODEL_LOAD_FORMAT\"]=\"UNCOMPRESSED\"\n",
        "#bert_preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')  # BERT\n",
        "bert_preprocess = hub.load('https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3')  # mBERT\n",
        "with strategy.scope():\n",
        "  #bert = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4', trainable=True)  # BERT\n",
        "  bert = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4', trainable=True)  # mBERT"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzgbTWyFN-G2"
      },
      "source": [
        "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
        "    \"\"\"Returns Model mapping string features to BERT inputs.\n",
        "    Args:\n",
        "    sentence_features: a list with the names of string-valued features.\n",
        "    seq_length: an integer that defines the sequence length of BERT inputs.\n",
        "\n",
        "    Returns:\n",
        "    A Keras Model that can be called on a list or dict of string Tensors\n",
        "    (with the order or names, resp., given by sentence_features) and\n",
        "    returns a dict of tensors for input to BERT.\n",
        "    \"\"\"\n",
        "\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "        for ft in sentence_features]\n",
        "\n",
        "    # Tokenize the text to word pieces.\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "\n",
        "    # Optional: Trim segments in a smart way to fit seq_length.\n",
        "    # Simple cases (like this example) can skip this step and let\n",
        "    # the next step apply a default truncation to approximately equal lengths.\n",
        "    truncated_segments = segments\n",
        "\n",
        "    # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
        "    # are model-dependent, so this gets loaded from the SavedModel.\n",
        "    packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                            arguments=dict(seq_length=seq_length),\n",
        "                            name='packer')\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    \n",
        "    return tf.keras.Model(input_segments,\n",
        "                          {'input_word_ids': model_inputs['input_word_ids'],\n",
        "                           'input_mask': model_inputs['input_mask'],\n",
        "                           'all_segment_id': model_inputs['input_type_ids']})\n",
        "\n",
        "\n",
        "preprocess_model = make_bert_preprocess_model(['text'], SEQ_LEN)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK8eTpjpQz9m",
        "outputId": "c17ca3bd-7d85-4798-fdc9-d7265ae9de4f"
      },
      "source": [
        "train_ds = train_ds.map(lambda feats, label: (preprocess_model(feats), label))\n",
        "dev_ds = dev_ds.map(lambda feats, label: (preprocess_model(feats), label))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:585: UserWarning: Input dict contained keys ['id', 'Health Sciences', 'Life Sciences', 'Multidisciplinary', 'Physical Sciences', 'Social Sciences & Humanities'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzxZY4RsTM-c"
      },
      "source": [
        "train_ds = train_ds.repeat(EPOCHS).cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNdUTtRHgG28"
      },
      "source": [
        "def build_classifier_model(max_seq_length=128):\n",
        "    \n",
        "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"all_segment_id\")\n",
        "    \n",
        "    outputs = bert({'input_word_ids': input_word_ids, 'input_mask': input_mask, 'input_type_ids': segment_ids})\n",
        "    net = outputs['pooled_output']\n",
        "    net = tf.keras.layers.Dropout(0.1)(net)\n",
        "    net = tf.keras.layers.Dense(num_classes, activation='sigmoid', name='classifier')(net)\n",
        "    \n",
        "    return tf.keras.Model(inputs={'input_word_ids': input_word_ids, 'input_mask': input_mask, 'all_segment_id': segment_ids}, outputs=net)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fmv4OmKRPXZ"
      },
      "source": [
        "def create_model():\n",
        "\n",
        "    model = build_classifier_model(SEQ_LEN)\n",
        "    \n",
        "    loss = tf.keras.losses.BinaryCrossentropy()\n",
        "    metrics = [F1Score(num_classes, average='micro', threshold=0.5, name='f1-micro'),\n",
        "               F1Score(num_classes, average='macro', threshold=0.5, name='f1-macro'),\n",
        "               tf.keras.metrics.Precision(),\n",
        "               tf.keras.metrics.Recall()]\n",
        "    \n",
        "    train_steps = train_steps_per_epoch * EPOCHS\n",
        "    num_warmup_steps = int(0.1*train_steps)\n",
        "\n",
        "    init_lr = 3e-5\n",
        "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')\n",
        "\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss=loss,\n",
        "                  metrics=metrics,\n",
        "                  steps_per_execution=100)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "    \n",
        "    model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath=CHECKPOINT_FPATH,\n",
        "        save_weights_only=True,\n",
        "        monitor='val_f1-micro',\n",
        "        mode='max',\n",
        "        save_best_only=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7tT_tf7UtZ3",
        "outputId": "6880ef85-97fe-41de-ec26-65e53bd64158"
      },
      "source": [
        "history = model.fit(train_ds,\n",
        "                    validation_data=dev_ds,\n",
        "                    steps_per_epoch=train_steps_per_epoch,\n",
        "                    validation_steps=dev_steps_per_epoch,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[], #[model_checkpoint_cb],  # set this to save the checkpoint from the best epoch\n",
        "                    verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"AdamWeightDecay/gradients/PartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"clip_by_global_norm/clip_by_global_norm/_0:0\", shape=(None, 768), dtype=float32), dense_shape=Tensor(\"AdamWeightDecay/gradients/PartitionedCall:2\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:449: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"while/AdamWeightDecay/gradients/PartitionedCall:1\", shape=(None,), dtype=int32), values=Tensor(\"while/clip_by_global_norm/while/clip_by_global_norm/_0:0\", shape=(None, 768), dtype=float32), dense_shape=Tensor(\"while/AdamWeightDecay/gradients/PartitionedCall:2\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "526/526 [==============================] - 121s 230ms/step - loss: 0.1564 - f1-micro: 0.8698 - f1-macro: 0.8645 - precision_1: 0.8730 - recall_1: 0.8666 - val_loss: 0.1436 - val_f1-micro: 0.9107 - val_f1-macro: 0.9159 - val_precision_1: 0.9215 - val_recall_1: 0.9002\n",
            "Epoch 2/5\n",
            "526/526 [==============================] - 39s 74ms/step - loss: 0.0575 - f1-micro: 0.9623 - f1-macro: 0.9648 - precision_1: 0.9695 - recall_1: 0.9553 - val_loss: 0.1540 - val_f1-micro: 0.9120 - val_f1-macro: 0.9170 - val_precision_1: 0.9153 - val_recall_1: 0.9087\n",
            "Epoch 3/5\n",
            "526/526 [==============================] - 39s 74ms/step - loss: 0.0365 - f1-micro: 0.9770 - f1-macro: 0.9786 - precision_1: 0.9816 - recall_1: 0.9725 - val_loss: 0.1561 - val_f1-micro: 0.9200 - val_f1-macro: 0.9252 - val_precision_1: 0.9137 - val_recall_1: 0.9264\n",
            "Epoch 4/5\n",
            "526/526 [==============================] - 39s 74ms/step - loss: 0.0206 - f1-micro: 0.9868 - f1-macro: 0.9875 - precision_1: 0.9892 - recall_1: 0.9844 - val_loss: 0.1699 - val_f1-micro: 0.9208 - val_f1-macro: 0.9254 - val_precision_1: 0.9189 - val_recall_1: 0.9226\n",
            "Epoch 5/5\n",
            "526/526 [==============================] - 39s 74ms/step - loss: 0.0108 - f1-micro: 0.9942 - f1-macro: 0.9945 - precision_1: 0.9959 - recall_1: 0.9924 - val_loss: 0.1718 - val_f1-micro: 0.9214 - val_f1-macro: 0.9261 - val_precision_1: 0.9189 - val_recall_1: 0.9239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEiggHg0pNld"
      },
      "source": [
        "# execute this only to load a pretrained checkpoint\n",
        "with strategy.scope():\n",
        "    model = create_model()\n",
        "    model.load_weights(CHECKPOINT_FPATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM_KOnmJjhXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00094729-4b88-4c7d-a297-0e99c21ea751"
      },
      "source": [
        "test_ds_orig = tf.data.experimental.make_csv_dataset(fpath_test, BATCH_SIZE, num_epochs=1, shuffle=False, field_delim=delim_test)\n",
        "topic_ids = list(test_ds_orig.element_spec.keys())[2:]\n",
        "\n",
        "test_ds_orig = test_ds_orig.unbatch()\n",
        "test_ds = test_ds_orig.map(prepare_multihot_label)\n",
        "test_ds = test_ds.batch(1)\n",
        "test_ds = test_ds.map(lambda feats, label: (preprocess_model(feats), label))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:585: UserWarning: Input dict contained keys ['id', 'Health Sciences', 'Life Sciences', 'Multidisciplinary', 'Physical Sciences', 'Social Sciences & Humanities'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4DfUUV1FoqS"
      },
      "source": [
        "test_ds = test_ds.unbatch()\n",
        "py_y_true = []\n",
        "for feats, label in test_ds:\n",
        "  py_y_true.append(label)\n",
        "y_true = tf.stack(py_y_true, axis=0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvsOtAGb9J8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c89de50-94b6-48bc-d041-0785ef7581cb"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "test_ds = test_ds.batch(BATCH_SIZE, drop_remainder=True)\n",
        "test_steps_per_epoch = int(n_test / BATCH_SIZE)\n",
        "y_pred = model.predict(test_ds, verbose=1, steps=test_steps_per_epoch)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 20s 87ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glkDF26bl8Ot"
      },
      "source": [
        "y_true = tf.round(y_true)\n",
        "y_pred = tf.cast(tf.round(y_pred), dtype=tf.int32)\n",
        "\n",
        "len_drop_remainder = int(len(y_true) / BATCH_SIZE) * BATCH_SIZE\n",
        "y_true = y_true[:len_drop_remainder]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJATXsgOVtO2"
      },
      "source": [
        "metric = MultiLabelConfusionMatrix(num_classes=num_classes)\n",
        "metric.update_state(y_true, y_pred)\n",
        "result = metric.result()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDbK2YAtb9ZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23b26af5-02d9-4d28-a455-c786acea5d92"
      },
      "source": [
        "print(f\"TOPIC\\tP (TP)\\tR (FP)\\tF1 (FN)\")\n",
        "total_tn, total_fp, total_fn, total_tp = 0, 0, 0, 0\n",
        "all_p, all_r, all_f1 = [], [], []\n",
        "for i_class, conf_matrix in enumerate(result):\n",
        "  tn, fp = conf_matrix[0]\n",
        "  fn, tp = conf_matrix[1]\n",
        "  #print(f\"TP:{tp}, FP:{fp}, FN:{fn}\")\n",
        "  p = tp / (tp + fp) if tp > 0 else 0.0\n",
        "  r = tp / (tp + fn) if tp > 0 else 0.0\n",
        "  f1 = (2 * p * r) / (p + r) if p + r > 0 else 0.0\n",
        "  all_p.append(p)\n",
        "  all_r.append(r)\n",
        "  all_f1.append(f1)\n",
        "  print(f\"{topic_ids[i_class]}\\t{p:.3f}\\t{r:.3f}\\t{f1:.3f}\")\n",
        "  #print(f\"{'':<16}\\t{tp}\\t{fp}\\t{fn}\")\n",
        "  total_tn += tn\n",
        "  total_fp += fp\n",
        "  total_fn += fn\n",
        "  total_tp += tp\n",
        "p_micro = total_tp / (total_tp + total_fp)\n",
        "r_micro = total_tp / (total_tp + total_fn)\n",
        "f1_micro = (2 * p_micro * r_micro) / (p_micro + r_micro)\n",
        "p_macro = sum(all_p) / len(all_p)\n",
        "r_macro = sum(all_r) / len(all_r)\n",
        "f1_macro = sum(all_f1) / len(all_f1)\n",
        "print(f\"TOTAL (micro)\\t{p_micro:.3f}\\t{r_micro:.3f}\\t{f1_micro:.3f}\")\n",
        "print(f\"TOTAL (macro)\\t{p_macro:.3f}\\t{r_macro:.3f}\\t{f1_macro:.3f}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOPIC\tP (TP)\tR (FP)\tF1 (FN)\n",
            "Health Sciences\t0.899\t0.904\t0.901\n",
            "Life Sciences\t0.868\t0.907\t0.887\n",
            "Multidisciplinary\t0.989\t0.983\t0.986\n",
            "Physical Sciences\t0.914\t0.922\t0.918\n",
            "Social Sciences & Humanities\t0.921\t0.917\t0.919\n",
            "TOTAL (micro)\t0.913\t0.922\t0.917\n",
            "TOTAL (macro)\t0.918\t0.926\t0.922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSFu9uM4rXZu"
      },
      "source": [
        "# Error analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiADunWdm5Ed"
      },
      "source": [
        "pids = []\n",
        "for p in test_ds_orig:\n",
        "  pids.append(p['id'].numpy().decode('utf-8'))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkMXgZ-RoEJt"
      },
      "source": [
        "id_preds = list(zip(pids, y_pred.numpy().tolist(), y_true.numpy().tolist()))\n",
        "random.shuffle(id_preds)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owEmVXGhoQ0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45567e33-7d3f-4ad0-e822-bf2f73089f54"
      },
      "source": [
        "N_PRINT = 15\n",
        "print(', '.join([ tid for tid in topic_ids]))\n",
        "print()\n",
        "print(f\"{'':<24}{' '.join([ tid[:6].upper() for tid in topic_ids])}\")\n",
        "print()\n",
        "for pid, _pred, _true in id_preds[:N_PRINT]:\n",
        "  print(f\"{pid:<24}{' '.join([ str(p)+'     ' for p in _pred ])}\")\n",
        "  print(f\"{'':<24}{' '.join([ str(p)+'     ' for p in _true ])}\")\n",
        "  print()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Health Sciences, Life Sciences, Multidisciplinary, Physical Sciences, Social Sciences & Humanities\n",
            "\n",
            "                        HEALTH LIFE S MULTID PHYSIC SOCIAL\n",
            "\n",
            "2-s2.0-77957805316      1      1      0      0      0     \n",
            "                        1      1      0      0      0     \n",
            "\n",
            "2-s2.0-84971222576      0      0      1      0      0     \n",
            "                        0      0      1      0      0     \n",
            "\n",
            "2-s2.0-34547412109      0      0      1      0      0     \n",
            "                        0      0      1      0      0     \n",
            "\n",
            "2-s2.0-33748771222      0      0      0      1      0     \n",
            "                        0      1      0      1      0     \n",
            "\n",
            "2-s2.0-72449172130      0      0      0      1      1     \n",
            "                        0      0      0      1      1     \n",
            "\n",
            "2-s2.0-84876412208      1      0      0      0      0     \n",
            "                        1      0      0      0      0     \n",
            "\n",
            "2-s2.0-84981312909      0      0      1      1      0     \n",
            "                        0      0      1      1      0     \n",
            "\n",
            "2-s2.0-84925248250      0      1      0      1      0     \n",
            "                        0      0      0      1      0     \n",
            "\n",
            "1902.09685              0      0      0      1      0     \n",
            "                        0      0      0      1      0     \n",
            "\n",
            "2-s2.0-70350432821      1      0      0      0      0     \n",
            "                        1      1      0      0      0     \n",
            "\n",
            "2-s2.0-84923092095      0      0      1      0      0     \n",
            "                        1      0      1      0      0     \n",
            "\n",
            "PMC6629150              0      1      0      1      0     \n",
            "                        1      0      0      0      0     \n",
            "\n",
            "2105.00337              0      0      0      0      1     \n",
            "                        0      0      0      0      1     \n",
            "\n",
            "PMC4423587              1      0      0      0      0     \n",
            "                        1      0      0      0      0     \n",
            "\n",
            "1910.03756              0      0      0      1      0     \n",
            "                        0      0      0      1      0     \n",
            "\n"
          ]
        }
      ]
    }
  ]
}